name: Benchmark

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:
  workflow_run:
    workflows: ["Test"]
    types:
      - completed

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  benchmark:
    name: Benchmark on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    # Only run if test passed, on release tags, or manually triggered
    if: ${{ github.event_name == 'workflow_dispatch' || github.event_name == 'push' || github.event.workflow_run.conclusion == 'success' }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        include:
          - os: ubuntu-latest
            python-version: '3.11'
          - os: macos-latest
            python-version: '3.11'
          - os: windows-latest
            python-version: '3.11'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Rust dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-benchmark-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-

      - name: Install uv
        uses: astral-sh/setup-uv@v5

      - name: Install Python dependencies
        run: |
          uv sync --dev

      - name: Build Rust extension (Release)
        run: |
          uv run maturin develop --release

      - name: Run benchmark tests
        run: |
          uv run pytest tests/test_benchmark.py::TestBenchmarkSummary::test_full_benchmark_report -v -s

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.os }}
          path: |
            benchmark-*.txt
            test-*.log
          retention-days: 30
          if-no-files-found: ignore

      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const os = '${{ matrix.os }}';

            // Try to read benchmark results if available
            let comment = `## ðŸ“Š Benchmark Results (${os})\n\n`;
            comment += 'Benchmark completed successfully. See artifacts for detailed results.';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
